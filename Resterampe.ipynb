{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idea of this notebook: \n",
    "\n",
    "Time series prediction of daily new Covid-Cases in Chile, with CASEN data as features\n",
    "\n",
    "Predict what?\n",
    "* For each region or for the whole country, predict future development (next five or ten days) of Covid cases/deaths\n",
    "* y = number of cases\n",
    "* x = casen data + more features (s. time series tips) \n",
    "\n",
    "data: CASEN data\n",
    "Covid data: from MINSAL\n",
    "\n",
    "\n",
    "1. Read in data: CASEN data, data from MINSAL about regions\n",
    "2. Data exploration\n",
    "3. Data visualization\n",
    "3. Metrics: low RSME (good for time series) \n",
    "4. Get features with high correlation\n",
    "5. build model with those features (maybe LR)\n",
    "6. GridSearch with different models (LR, Kregressor, RandomForestRegressor) \n",
    "7. Findings/conclusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read in data about Covid-19 in Chilean districts\n",
    "cases_districts = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto1/Covid-19.csv')\n",
    "cases_districts = cases_districts[~cases_districts.Comuna.str.contains('Desconocido')]\n",
    "\n",
    "\n",
    "deaths_districts = pd.read_csv(\n",
    "    'https://raw.githubusercontent.com/MinCiencia/Datos-COVID19/master/output/producto38/CasosFallecidosPorComuna.csv')\n",
    "deaths_districts = deaths_districts[~deaths_districts.Comuna.str.contains('Desconocido')]\n",
    "deaths_districts = deaths_districts[~deaths_districts.Comuna.str.contains('Total')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeline_plot(df, title):\n",
    "    \"\"\"\n",
    "    A function to plot a seaborn diagram which shows the development of Covid-19 data in Chilean Regions. \n",
    "    For better readability, the function returns a log scale plot. \n",
    "    \n",
    "    Input: \n",
    "        df (DataFrame): A DataFrame whith information about Covid-19 in Chile.\n",
    "        title (string): Specify the kind of the plot (cases or deaths)\n",
    "        \n",
    "    Output: \n",
    "        A seaborn plot. \n",
    "    \"\"\"\n",
    "\n",
    "    # Get only relevant columns with information about cases/deaths:     \n",
    "    df_numbers = df[df.columns[5:-1]]\n",
    "    df_final = pd.concat([df['Region'], df_numbers], axis = 1)\n",
    "\n",
    "    # Group by region to get total numbers for each region. \n",
    "    df_grouped = df_final.groupby('Region')[[i for i in df_final.columns[1:]]].sum().reset_index()\n",
    "\n",
    "    # Apply melt, convert Date-column to datetime and sort values\n",
    "    df_melt = pd.melt(df_grouped, id_vars = 'Region', \n",
    "                       value_vars = df_grouped.columns.drop('Region'),\n",
    "                       var_name='Date', \n",
    "                       value_name='Cases')\n",
    "\n",
    "    df_melt.loc[:, ['Date']] = pd.to_datetime(df_melt['Date'])\n",
    "    df_melt = df_melt.sort_values('Cases', ascending = False)\n",
    "\n",
    "    # Plot the timeline\n",
    "    f, ax = plt.subplots(figsize = (16, 12))\n",
    "\n",
    "    g = sns.lineplot(\n",
    "        df_melt.Date, \n",
    "        df_melt.Cases, \n",
    "        hue = df_melt.Region\n",
    "    )\n",
    "\n",
    "    plt.xlabel('Date', fontsize = 20)\n",
    "    plt.ylabel('{} (log scale)'.format(title), fontsize = 20)\n",
    "    plt.title('Covid-19 {} in Chile (log scale)'.format(title), fontsize = 25)\n",
    "\n",
    "    ax.yaxis.tick_right()\n",
    "    ax.set_yscale('log')\n",
    "    plt.tick_params(labelsize=20, rotation=90)\n",
    "    plt.legend(scatterpoints=1, frameon=True, labelspacing=.2, bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.5)\n",
    "\n",
    "    plt.grid(False)\n",
    "    ax.yaxis.grid()\n",
    "    sns.despine()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #(np.sum(casen.isna() == True)/casen.shape[0]).sort_values(ascending = False).head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobility_chile_target = mobility_chile[mobility_chile['sub_region_1'] == target]\n",
    "\n",
    "merged_mobility = df_sel.merge(mobility_chile_target, left_on = 'Region', right_on = 'date', how = 'left')\n",
    "merged_mobility = merged_mobility.drop(['sub_region_1', 'date'], axis = 1)\n",
    "merged_mobility = merged_mobility[~merged_mobility['retail_and_recreation_percent_change_from_baseline'].isna()]\n",
    "\n",
    "merged_mobility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transposed_cases.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = []\n",
    "for day in range(3, 157):\n",
    "    train = df_mobility[df_mobility['days'] < day]\n",
    "    val = df_mobility[df_mobility['days'] == day]\n",
    "\n",
    "    p = val['yesterday_value'].values\n",
    "\n",
    "    error = rmsle(val['cases'].values, p)\n",
    "    print('day %d - Error %.5f' % (day, error))\n",
    "    mean_error.append(error)\n",
    "print('Mean Error = %.5f' % np.mean(mean_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#    mobility_df = prepare_mobility_data(df, 'Germany', '2020-04-04', '2020-08-07', include_regions=False, drop_date=False)\n",
    " #       sns.lineplot(x = mobility_chile_all['date'], y = mobility_chile_all['grocery_and_pharmacy_percent_change_from_baseline'])\n",
    "  #      sns.lineplot(x = mobility_chile_all['date'], y = mobility_chile_all['transit_stations_percent_change_from_baseline'])\n",
    "   #     sns.lineplot(x = mobility_chile_all['date'], y = mobility_chile_all['parks_percent_change_from_baseline'])\n",
    "    #    sns.lineplot(x = mobility_chile_all['date'], y = mobility_chile_all['workplaces_percent_change_from_baseline'])\n",
    "     #   sns.lineplot(x = mobility_chile_all['date'], y = mobility_chile_all['residential_percent_change_from_baseline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sub_region_1'] = df['sub_region_1'].map({\n",
    "                                                'Tarapacá': 'Tarapacá',\n",
    "                                                'Antofagasta': 'Antofagasta',\n",
    "                                                'Atacama': 'Atacama',\n",
    "                                                'Coquimbo': 'Coquimbo',\n",
    "                                                'Valparaíso': 'Valparaíso',\n",
    "                                                \"O'Higgins\": 'O’Higgins',\n",
    "                                                'Maule': 'Maule',\n",
    "                                                'Bio Bio': 'Biobío',\n",
    "                                                'Araucania': 'Araucanía', \n",
    "                                                'Los Lagos': 'Los Lagos',\n",
    "                                                'Aysén': 'Aysén',\n",
    "                                                'Magallanes and Chilean Antarctica': 'Magallanes',\n",
    "                                                'Santiago Metropolitan Region': 'Metropolitana',\n",
    "                                                'Los Ríos': 'Los Ríos',\n",
    "                                                'Arica y Parinacota': 'Arica y Parinacota',\n",
    "                                                'Ñuble': 'Ñuble'\n",
    "                                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "mobility['sub_region_1'] = mobility['sub_region_1'].map({\n",
    "    'Tarapacá': 'Tarapacá',\n",
    "    'Antofagasta': 'Antofagasta',\n",
    "    'Atacama': 'Atacama',\n",
    "    'Coquimbo': 'Coquimbo',\n",
    "    'Valparaíso': 'Valparaíso',\n",
    "    \"O'Higgins\": 'O’Higgins',\n",
    "    'Maule': 'Maule',\n",
    "    'Bio Bio': 'Biobío',\n",
    "    'Araucania': 'Araucanía', \n",
    "    'Los Lagos': 'Los Lagos',\n",
    "    'Aysén': 'Aysén',\n",
    "    'Magallanes and Chilean Antarctica': 'Magallanes',\n",
    "    'Santiago Metropolitan Region': 'Metropolitana',\n",
    "    'Los Ríos': 'Los Ríos',\n",
    "    'Arica y Parinacota': 'Arica y Parinacota',\n",
    "    'Ñuble': 'Ñuble'\n",
    "})\n",
    "\n",
    "mobility_chile = mobility[(mobility['country_region'] == 'Chile') & (~mobility['sub_region_1'].isna())]\n",
    "\n",
    "mobility_chile = mobility_chile.drop([\n",
    "    'country_region',\n",
    "    'country_region_code', \n",
    "    'sub_region_2', \n",
    "    'metro_area', \n",
    "    'iso_3166_2_code', \n",
    "    'census_fips_code'\n",
    "], axis = 1)\n",
    "\n",
    "mobility_chile.loc[:, 'date'] = pd.to_datetime(mobility_chile.loc[:, 'date'])\n",
    "\n",
    "# Convert mobility columns to float\n",
    "info_columns = ['retail_and_recreation_percent_change_from_baseline', \n",
    "                'grocery_and_pharmacy_percent_change_from_baseline',\n",
    "               'parks_percent_change_from_baseline',\n",
    "               'transit_stations_percent_change_from_baseline',\n",
    "               'workplaces_percent_change_from_baseline',\n",
    "               'residential_percent_change_from_baseline']\n",
    "\n",
    "mobility_chile[info_columns] = mobility_chile[info_columns].astype(float)\n",
    "\n",
    "mobility_chile = mobility_chile.groupby(['sub_region_1', 'date'])[info_columns].mean().reset_index()\n",
    "\n",
    "mobility_chile = mobility_chile[(mobility_chile['date'] >= '2020-03-04') & (mobility_chile['date'] <= '2020-08-07')]\n",
    "\n",
    "mobility_chile['days'] = 0\n",
    "\n",
    "mobility_chile = mobility_chile.assign(days = np.arange(len(mobility_chile)) % 157)\n",
    "\n",
    "mobility_chile = mobility_chile.drop(['date'], axis = 1)\n",
    "\n",
    "mobility_chile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define rsmle\n",
    "\n",
    "def rmsle(ytrue, ypred):    \n",
    "    return np.sqrt(mean_squared_log_error(ytrue, ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cases_regions.copy()\n",
    "title = 'cases'\n",
    "\n",
    "\n",
    "\n",
    "df = df[(df['Region'] >= '2020-03-04') & (df['Region'] <= '2020-08-07')]\n",
    "\n",
    "df.insert(0, 'days', range(len(df)))\n",
    "\n",
    "df = df.drop(['Region'], axis = 1)\n",
    "\n",
    "\n",
    "df_melt = pd.melt(\n",
    "    df, id_vars = ['days'], \n",
    "    value_vars = df.columns.drop(['days']), \n",
    "    value_name=title\n",
    ")\n",
    "\n",
    "df_melt = df_melt.loc[df_melt['variable'] != 'Total', :]\n",
    "\n",
    "df_melt['yesterday_value'] = df_melt.groupby('variable')[title].shift()\n",
    "\n",
    "df_melt['yesterday_diff'] = df_melt.groupby('variable')['yesterday_value'].diff()\n",
    "\n",
    "df_mobility = df_melt.merge(mobility_chile, left_on = ['days', 'variable'], right_on = ['days', 'sub_region_1'], how = 'left')\n",
    "\n",
    "df_mobility = df_mobility.drop(['sub_region_1'], axis = 1)\n",
    "\n",
    "df_mobility = df_mobility.fillna(method = 'bfill', axis = 0)\n",
    "\n",
    "df_mobility.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge mobility and cases data with CASEN social indicators\n",
    "df_mobility_casen = df_mobility.merge(casen_regions, left_on = 'variable', right_on = 'region', how = 'left')\n",
    "\n",
    "# Make dummy columns for regions: \n",
    "region_dummies = pd.get_dummies(df_mobility_casen['variable'])\n",
    "\n",
    "df_mobility_casen_dummies = pd.concat([df_mobility_casen, region_dummies], axis = 1)\n",
    "\n",
    "df_mobility_casen_dummies = df_mobility_casen_dummies.drop(['variable', 'region'], axis = 1)\n",
    "\n",
    "df_mobility_casen_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To make sure the model is worth using I like to set a baseline score that it has to beat. In this case, \n",
    "# a reasonably strong baseline is using the last week amount of sales as a prediction for the sales this week.\n",
    "# Baseline\n",
    "\n",
    "mean_error = []\n",
    "for day in range(3, 157):\n",
    "    train = df_mobility_casen_dummies[df_mobility_casen_dummies['days'] < day]\n",
    "    val = df_mobility_casen_dummies[df_mobility_casen_dummies['days'] == day]\n",
    "\n",
    "    p = val['yesterday_value'].values\n",
    "    \n",
    "    error = rmsle(val['yesterday_diff'].values, p)\n",
    "    print('day %d - Error %.5f' % (day, error))\n",
    "    mean_error.append(error)\n",
    "print('Mean Error = %.5f' % np.mean(mean_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_mobility_casen_dummies['yesterday_diff']\n",
    "X = df_mobility_casen_dummies.drop(['yesterday_diff'], axis = 1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_error = []\n",
    "for day in range(3, 157):\n",
    "\n",
    "    mdl = RandomForestRegressor(n_estimators=10, n_jobs=-1, random_state=0)\n",
    "    mdl.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = mdl.predict(X_test)\n",
    "\n",
    "    error = rmsle(y_test, y_pred)\n",
    "    print('day %d - Error %.5f' % (day, error))\n",
    "    mean_error.append(error)\n",
    "print('Mean Error = %.5f' % np.mean(mean_error))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(actual, predict):\n",
    "    \"\"\"\n",
    "    Function \n",
    "    \"\"\"\n",
    "    \n",
    "    predict = np.array(predict)\n",
    "    actual = np.array(actual)\n",
    "    distance = predict - actual\n",
    "    square_distance = distance ** 2\n",
    "    mean_square_distance = square_distance.mean()\n",
    "    score = np.sqrt(mean_square_distance)\n",
    "    return score\n",
    "\n",
    "rmse_score = make_scorer(rmse, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "\n",
    "param_search = { \n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [i for i in range(5,15)]\n",
    "}\n",
    "\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "param_search = { \n",
    "    'n_neighbors': [5, 7, 10, 13, 20, 30, 50],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'leaf_size': [10, 30, 50]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train and test set: Training set from March to June (4 months), validation July (1 month)\n",
    "X_train = df_melt_mobility_num[:'2020-06-30'].drop(['new_cases'], axis = 1)\n",
    "y_train = df_melt_mobility_num.loc[:'2020-06-30', 'new_cases']\n",
    "X_test = df_melt_mobility_num['2020-07-01':].drop(['new_cases'], axis = 1)\n",
    "y_test = df_melt_mobility_num.loc['2020-07-01':, 'new_cases']\n",
    "\n",
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tryout of some models (https://towardsdatascience.com/time-series-modeling-using-scikit-pandas-and-numpy-682e3b8db8d1)\n",
    "\n",
    "# Store models in list\n",
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('KNN', KNeighborsRegressor())) \n",
    "models.append(('RF', RandomForestRegressor(n_estimators = 100, random_state = 42)))\n",
    "models.append(('SVR', SVR(gamma='auto')))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\n",
    "    # TimeSeries split\n",
    "    tscv = TimeSeriesSplit(n_splits=12)\n",
    "\n",
    "    # TimeSeries Cross validation\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=tscv, scoring='r2')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    \n",
    "    # Print results\n",
    "    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    "    \n",
    "    # Plot boxplot for each model\n",
    "plt.boxplot(results, labels=names)\n",
    "plt.title('Algorithm Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = KNeighborsRegressor()\n",
    "\n",
    "param_search = { \n",
    "    'n_neighbors': [5, 7, 10, 13, 20, 30, 50],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "    'leaf_size': [10, 30, 50]\n",
    "}\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=12)\n",
    "\n",
    "gsearch = GridSearchCV(\n",
    "    estimator=model, \n",
    "    cv=tscv, \n",
    "    param_grid=param_search, \n",
    "    scoring = rmse_score)\n",
    "\n",
    "gsearch.fit(X_train, y_train)\n",
    "\n",
    "best_score = gsearch.best_score_\n",
    "best_model = gsearch.best_estimator_\n",
    "\n",
    "y_true = y_test.values\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(best_model)\n",
    "\n",
    "regression_metrics(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = best_model.feature_importances_[:10]\n",
    "features = X_train.columns\n",
    "\n",
    "indices = np.argsort(imp)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), imp[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(figsize = (12,8))\n",
    "plt.scatter(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "\n",
    "param_search = { \n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [i for i in range(5,15)]\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=12)\n",
    "\n",
    "gsearch = GridSearchCV(\n",
    "    estimator=model, \n",
    "    cv=tscv, \n",
    "    param_grid=param_search, \n",
    "    scoring = rmse_score)\n",
    "\n",
    "gsearch.fit(X_train_CASEN, y_train_CASEN)\n",
    "\n",
    "best_score = gsearch.best_score_\n",
    "best_model = gsearch.best_estimator_\n",
    "\n",
    "y_true_CASEN = y_test_CASEN.values\n",
    "y_pred_CASEN = best_model.predict(X_test_CASEN)\n",
    "\n",
    "print(best_model)\n",
    "\n",
    "regression_metrics(y_true_CASEN, y_pred_CASEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix, ax = plt.subplots(figsize = (16,10))\n",
    "plt.scatter(y_true_CASEN, y_pred_CASEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = best_model.feature_importances_[:10]\n",
    "features = X_train.columns\n",
    "\n",
    "indices = np.argsort(imp)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), imp[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare train and test set: Training set from March to June (4 months), validation July (1 months)\n",
    "X_train = df_melt_mobility_num[:'2020-06-30'].drop(['new_deaths'], axis = 1)\n",
    "y_train = df_melt_mobility_num.loc[:'2020-06-30', 'new_deaths']\n",
    "X_test = df_melt_mobility_num['2020-07-01':].drop(['new_deaths'], axis = 1)\n",
    "y_test = df_melt_mobility_num.loc['2020-07-01':, 'new_deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store models in list\n",
    "models = []\n",
    "models.append(('LR', LinearRegression()))\n",
    "models.append(('KNN', KNeighborsRegressor())) \n",
    "models.append(('RF', RandomForestRegressor(n_estimators = 100, random_state = 42)))\n",
    "models.append(('SVR', SVR(gamma='auto')))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "\n",
    "    # TimeSeries split, n_splits = 6\n",
    "    tscv = TimeSeriesSplit(n_splits=12)\n",
    "\n",
    "    # TimeSeries Cross validation\n",
    "    cv_results = cross_val_score(model, X_train, y_train, cv=tscv, scoring='r2')\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    \n",
    "    # Print results\n",
    "    print('%s: %f (%f)' % (name, cv_results.mean(), cv_results.std()))\n",
    "    \n",
    "    # Plot boxplot for each model\n",
    "plt.boxplot(results, labels=names)\n",
    "plt.title('Algorithm Comparison')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "\n",
    "param_search = { \n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [i for i in range(5,15)]\n",
    "}\n",
    "\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=12)\n",
    "\n",
    "gsearch = GridSearchCV(\n",
    "    estimator=model, \n",
    "    cv=tscv, \n",
    "    param_grid=param_search, \n",
    "    scoring = rmse_score)\n",
    "\n",
    "gsearch.fit(X_train, y_train)\n",
    "\n",
    "best_score = gsearch.best_score_\n",
    "best_model = gsearch.best_estimator_\n",
    "\n",
    "y_true = y_test.values\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(best_model)\n",
    "\n",
    "regression_metrics(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = best_model.feature_importances_[:10]\n",
    "features = X_train.columns\n",
    "\n",
    "indices = np.argsort(imp)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), imp[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "\n",
    "param_search = { \n",
    "    'n_estimators': [20, 50, 100],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [i for i in range(5,15)]\n",
    "}\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits=12)\n",
    "\n",
    "gsearch = GridSearchCV(\n",
    "    estimator=model, \n",
    "    cv=tscv, \n",
    "    param_grid=param_search, \n",
    "    scoring = rmse_score)\n",
    "\n",
    "gsearch.fit(X_train_CASEN, y_train_CASEN)\n",
    "\n",
    "best_score = gsearch.best_score_\n",
    "best_model = gsearch.best_estimator_\n",
    "\n",
    "y_true_CASEN = y_test_CASEN.values\n",
    "y_pred_CASEN = best_model.predict(X_test_CASEN)\n",
    "\n",
    "print(best_model)\n",
    "\n",
    "regression_metrics(y_true_CASEN, y_pred_CASEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp = best_model.feature_importances_[:10]\n",
    "features = X_train.columns\n",
    "\n",
    "indices = np.argsort(imp)\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), imp[indices], color='b', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
